{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "pip install pdfplumber"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkoKPjQQSGgH",
    "outputId": "62d6b2b5-17a2-4357-a237-b721739bbc6d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20251107 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
      "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqnVis57VBn3"
   },
   "outputs": [],
   "source": [
    "import re, json\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "OHzaqo3ScJq7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "outputId": "4df65f8b-7197-4ca5-9a96-876b5ae68d21"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "MessageError",
     "evalue": "Error: credential propagation was unsuccessful",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_main_dic():\n",
    "\n",
    "    L1_dic={\"BidMonthYear\": None,\n",
    "            \"Fleet\":None, \"Base\":None,\n",
    "            \"Effective Date\": None,\n",
    "            \"Through Date\": None,\n",
    "            \"Pairings\": [],\n",
    "            \"FTM\": None,\n",
    "            \"TTL\": None\n",
    "                     }\n",
    "\n",
    "    return L1_dic\n",
    "\n",
    "\n",
    "def create_pairing_dic():\n",
    "    L2_dic = {\n",
    "        \"ID\": None,\n",
    "        \"Pairing Category\": None,\n",
    "        \"F/O\": None,\n",
    "        \"Effective Date\": None,\n",
    "        \"Through Date\": None,\n",
    "        \"Date Instances\": [],\n",
    "        \"Duty Periods\": [],\n",
    "        \"Days\": None,\n",
    "        \"Credit\": None,\n",
    "        \"Flight Time\": None,\n",
    "        \"Time Away From Base\": None,\n",
    "        \"International Flight Time\": None,\n",
    "        \"NTE\": None,\n",
    "        \"M$\": None,\n",
    "        \"T/C\": None\n",
    "    }\n",
    "    return L2_dic\n",
    "\n",
    "def create_duty_periods_dic():\n",
    "\n",
    "    L3_dic= {\n",
    "        \"Report\": None ,\n",
    "        \"LEGS\": [],\n",
    "        \"Release Time\": None\n",
    "    }\n",
    "\n",
    "    return L3_dic\n",
    "\n",
    "def create_legs_dic():\n",
    "\n",
    "    L4_dic= {\n",
    "\n",
    "        \"Equipment\": None,\n",
    "        \"Deadhead\": None,\n",
    "        \"Flight Number\": None,\n",
    "        \"Departure Station\": None,\n",
    "        \"Arrival Station\": None,\n",
    "        \"Departure Time\": None,\n",
    "        \"Arrival Time\": None,\n",
    "        \"Ground Time\": None,\n",
    "        \"Meal Code\": None,\n",
    "        \"Flight Time\": None,\n",
    "        \"Accumulated Flight Time\": None,\n",
    "        \"Duty Time\": None,\n",
    "        \"D/C\": None\n",
    "    }\n",
    "    return L4_dic\n",
    "\n",
    "def create_master_dic():\n",
    "\n",
    "    master_dic= {\n",
    "\n",
    "        \"data\": []\n",
    "    }\n",
    "    return master_dic\n"
   ],
   "metadata": {
    "id": "8dXzkRZYVLrr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import re, json\n\ndef airline_pairing_processor(input_path, output_path):\n\n    try:\n        # Open and extract text from the PDF\n        with pdfplumber.open(input_path) as pdf:\n            raw_lines = []\n            for page in pdf.pages:\n                text = page.extract_text() or \"\"\n                raw_lines.extend(text.splitlines())\n\n    except Exception as e:\n        print(f\"Error reading PDF: {e}\")\n        return\n\n    # raw_lines now contains a list of text lines exactly like your .dat workflow\n    print(\"Successfully read PDF with\", len(raw_lines), \"lines\")\n\n\n\n    # Initiate a five level state structure using dictionaries\n\n    Master_dic= create_master_dic()\n    L1_dic= create_main_dic()\n    L2_dic= create_pairing_dic()\n    L3_dic= create_duty_periods_dic()\n    L4_dic= create_legs_dic()\n\n    # Iterate line-by-line thru the text data and identify unique sections and store them in their relevant sports.\n\n    for line in raw_lines:\n        if \"1DSL\" in line: #Pairing Header line\n            L1_dic['BidMonthYear']=line[68:78].strip()\n            L1_dic['Fleet']= line[35:38].strip()\n            L1_dic['Base']= line[42:55].strip()\n            L1_dic['Effective Date']= line[9:17].strip()\n            L1_dic['Through Date']= line[23:31].strip()\n\n        if \"FTM\" in line and \"TTL\" in line:\n\n            pattern_with_codes = r\"(FTM|TTL)-\\s*(\\d{1,}(?:,\\d{1,})*:\\d{2})\"\n            matches_with_codes = re.findall(pattern_with_codes, line)\n            L1_dic['FTM']= matches_with_codes[0][1]\n            L1_dic['TTL']= matches_with_codes[1][1]\n\n            Master_dic[\"data\"].append(L1_dic)\n            L1_dic=create_main_dic()\n\n        if \"|\" in line and \"SU\" not in line: # Indicates a calendar info line aka date instances. We are also avoiding the header line\n\n            digit_pattern = r\"(\\d+)\"\n            L2_dic['Date Instances'].extend(re.findall(digit_pattern, line[109:129]))\n\n        if \"1DSL\" not in line and \"EFF\" in line: # Start of Pairing\n\n            substring= line[1:109] # Captures multiple lines, to expand the comment here\n            pattern_extraction = r\"EFF (\\d{2}/\\d{2}/\\d{2}) THRU (\\d{2}/\\d{2}/\\d{2}).*?(F/O)?\\s*ID (\\w+)\\s+-\\s+(\\w+)(?:\\s+\\((\\w+)\\))?(\\s*)?\"\n            matches_extraction = re.search(pattern_extraction, substring)\n            if matches_extraction:\n                eff_date, thru_date, fo_presence, id_value, category, optional_content, _ = matches_extraction.groups()\n                L2_dic[\"Effective Date\"]= eff_date\n                L2_dic['Through Date']= thru_date\n                L2_dic['F/O']= bool(fo_presence)\n                L2_dic['ID']= id_value\n                L2_dic['Pairing Category']= category + (f\" ({optional_content})\" if optional_content else \"\")\n\n\n\n        if \"RPT:\" in line:\n\n            pattern_report = r\"RPT:\\s*(\\d+)\"\n            match_report = re.search(pattern_report, line[:109])\n            L3_dic['Report']=match_report.group(1)\n\n        if line[4:6].isdigit() and line[6].isalpha(): # Identify a leg entry\n\n            L4_dic[\"Equipment\"]= line[4:7]\n            L4_dic[\"Deadhead\"]= \"DH\" in line\n            L4_dic[\"Flight Number\"]= line[11:15].strip()\n            L4_dic[\"Departure Station\"]= line[16:19]\n            L4_dic[\"Arrival Station\"]= line[20:23]\n            L4_dic[\"Meal Code\"]= line[41].strip()\n            L4_dic[\"Departure Time\"]= line[24:28].strip()\n            L4_dic[\"Arrival Time\"]= line[29:33].strip()\n            L4_dic[\"Ground Time\"]= (lambda x: '0' if x == '.00' else x.replace('.', ':'))(line[35:40].strip())\n            L4_dic[\"Flight Time\"]= (lambda x: '0' if x == '.00' else x.replace('.', ':'))(line[48:53].strip())\n            L4_dic[\"Accumulated Flight Time\"]= (lambda x: '0' if x == '.00' else x.replace('.', ':'))(line[53:59].strip())\n            L4_dic[\"Duty Time\"]= (lambda x: '0' if x == '.00' else x.replace('.', ':'))(line[61:66].strip())\n            L4_dic[\"D/C\"]= (lambda x: '0' if x == '.00' else x.replace('.', ':'))(line[71:75].strip())\n\n            L3_dic[\"LEGS\"].append(L4_dic.copy()) # Append complete leg info into the list of dictionaries of the pairing dictionary\n            L4_dic= create_legs_dic() # Cleare the leg dictionary for the next leg.\n\n\n            continue\n\n        if \"RLS:\" in line: # End of leg and RLS line\n\n            pattern_report = r\"RLS:\\s*(\\d+)\"\n            match_report = re.search(pattern_report, line[:109])\n            L3_dic['Release Time']=match_report.group(1)\n\n\n            L2_dic['Duty Periods'].append(L3_dic.copy())\n            L3_dic= create_duty_periods_dic() # Clear duty periods dictionary for the next duty period\n\n\n        if \"DAYS-\" in line: # This will also indicate an end of a pairing\n\n            patterns = {\n        \"Days\": r\"DAYS-\\s*(\\d+)\",\n        \"Credit\": r\"CRD-\\s*([\\d\\.]+)\",\n        \"Flight Time\": r\"FTM-\\s*([\\d\\.:]+)\",\n        \"Time Away From Base\": r\"TAFB-\\s*([\\d\\.:]+)\",\n        \"International Flight Time\": r\"INT-\\s*([\\d\\.]+)\",\n        \"NTE\": r\"NTE-\\s*([\\d\\.]+)\",\n        \"M$\": r\"M\\$\\-\\s*([\\d\\.]+)\",\n        \"T/C\": r\"T/C-\\s*([\\d\\.]+)\"\n    }\n\n            # Extracting the values using the regex patterns\n            extracted_values = {}\n            for label, pattern in patterns.items():\n                match = re.search(pattern, line)\n                if match:\n                    extracted_values[label] = match.group(1)\n\n            # Storing the extracted values in the L2_dic\n            for key in extracted_values:\n\n                if key in L2_dic:\n                    L2_dic[key] = extracted_values[key]\n\n            L1_dic[\"Pairings\"].append(L2_dic.copy())\n            L2_dic=create_pairing_dic() # Creates a fresh pairing dictionary for the next iterartion\n\n\n    with open(output_path, \"w\") as json_file:\n        json_file.write(json.dumps(Master_dic, indent=4))\n        print('Pairing Successfuly completed and saved in ', str(output_path))",
   "metadata": {
    "id": "4KgXfsXsVOz7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "airline_pairing_processor(\"p_ORD73701_upd.pdf\", \"ORD_output.json\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "jZVvwQMYVRLn",
    "outputId": "38643cf2-608a-4a7b-cd2d-dd11f366b2df"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully read PDF with 20498 lines\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'eff_date' where it is not associated with a value",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1148217686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mairline_pairing_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p_ORD73701_upd.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ORD_output.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-3176520431.py\u001b[0m in \u001b[0;36mairline_pairing_processor\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmatches_extraction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0meff_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthru_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfo_presence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mL2_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Effective Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0meff_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mL2_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Through Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mthru_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mL2_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F/O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo_presence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'eff_date' where it is not associated with a value"
     ]
    }
   ]
  }
 ]
}